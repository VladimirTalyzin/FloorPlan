{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-11-24T11:48:16.571991Z",
     "iopub.status.busy": "2022-11-24T11:48:16.571465Z",
     "iopub.status.idle": "2022-11-24T11:48:30.248365Z",
     "shell.execute_reply": "2022-11-24T11:48:30.246822Z",
     "shell.execute_reply.started": "2022-11-24T11:48:16.571909Z"
    },
    "id": "lkfIbMUIUcbO",
    "outputId": "b314547e-eed3-4fc7-feff-edbf5039e698"
   },
   "outputs": [],
   "source": [
    "# Загружаем модули. Добавлены параметры, чтобы не засорять ноутбук сообщениями, не имеющими никакого отношения к решению\n",
    "!pip install segmentation_models --root-user-action=ignore > /dev/null\n",
    "!pip install keras-unet-collection --root-user-action=ignore > /dev/null\n",
    "!pip install albumentations --root-user-action=ignore > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T11:48:30.251843Z",
     "iopub.status.busy": "2022-11-24T11:48:30.251382Z",
     "iopub.status.idle": "2022-11-24T11:48:33.891729Z",
     "shell.execute_reply": "2022-11-24T11:48:33.890533Z",
     "shell.execute_reply.started": "2022-11-24T11:48:30.251814Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "# Подключаем модули\n",
    "import os\n",
    "from random import seed, shuffle\n",
    "import cv2\n",
    "import keras.backend as K\n",
    "import segmentation_models as sm\n",
    "import tensorflow as tf\n",
    "from albumentations import Compose, ShiftScaleRotate, HueSaturationValue, RandomGamma, Sharpen, Blur, HorizontalFlip, VerticalFlip, RandomBrightnessContrast, CLAHE, ImageCompression, MultiplicativeNoise\n",
    "from keras.callbacks import EarlyStopping\n",
    "from numpy import array, zeros, expand_dims, uint8\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from tqdm.keras import TqdmCallback\n",
    "from keras.losses import binary_crossentropy\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T11:48:33.893522Z",
     "iopub.status.busy": "2022-11-24T11:48:33.892989Z",
     "iopub.status.idle": "2022-11-24T11:48:33.898569Z",
     "shell.execute_reply": "2022-11-24T11:48:33.897550Z",
     "shell.execute_reply.started": "2022-11-24T11:48:33.893496Z"
    }
   },
   "outputs": [],
   "source": [
    "# Глобальные настройки решения\n",
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH  = 512\n",
    "\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "SEED = 500\n",
    "\n",
    "THRESHOLD = 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T11:48:33.901354Z",
     "iopub.status.busy": "2022-11-24T11:48:33.901107Z",
     "iopub.status.idle": "2022-11-24T11:48:33.908137Z",
     "shell.execute_reply": "2022-11-24T11:48:33.907156Z",
     "shell.execute_reply.started": "2022-11-24T11:48:33.901327Z"
    }
   },
   "outputs": [],
   "source": [
    "# Функция потери - DiceLoss + BinaryCrossEntropy\n",
    "def diceLoss(targetsPure, inputsPure):\n",
    "    targets = tf.cast(K.flatten(targetsPure), tf.float32)\n",
    "    inputs = tf.cast(K.flatten(inputsPure), tf.float32)\n",
    "\n",
    "    intersection = K.sum(targets * inputs)\n",
    "    dice = (2 * intersection + 1e-6) / (K.sum(targets) + K.sum(inputs) + 1e-6)\n",
    "    return 1 - dice\n",
    "\n",
    "\n",
    "def bceDiceLoss(y_true, y_pred):\n",
    "    return K.mean(binary_crossentropy(y_true, y_pred)) + diceLoss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T11:48:33.909892Z",
     "iopub.status.busy": "2022-11-24T11:48:33.909560Z",
     "iopub.status.idle": "2022-11-24T11:49:28.706749Z",
     "shell.execute_reply": "2022-11-24T11:49:28.705709Z",
     "shell.execute_reply.started": "2022-11-24T11:48:33.909865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnext101_imagenet_1000_no_top.h5\n",
      "173622728/173622728 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Все настройки обучения и работы с моделями\n",
    "MODEL_TAG = \"resnext101\"\n",
    "\n",
    "classes = \\\n",
    "{\n",
    "    \"wall\":\n",
    "    {\n",
    "        \"classNumber\": 1,\n",
    "        'model': sm.Unet(\"resnext101\", classes = 1, activation = 'sigmoid'),\n",
    "        'train': True,\n",
    "        \"continue-train\": True,\n",
    "        \"max-train-images\": 4000,\n",
    "\n",
    "        \"optimizer\": tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "        \"loss\": bceDiceLoss,\n",
    "        \"metrics\": [sm.metrics.iou_score],\n",
    "        \"saved-model\": \"models-\" + MODEL_TAG + \"-wall/unet.ckpt\",\n",
    "        \"batch-size\": 4,\n",
    "        \"epochs\": 10,\n",
    "        \"callbacks\": [EarlyStopping(monitor = 'val_iou_score', mode = 'max', patience = 4, verbose = 0, restore_best_weights = True)],\n",
    "\n",
    "        \"max-percent\": 0.4,\n",
    "        \n",
    "        \"transforms\": Compose(\n",
    "        [  \n",
    "            RandomGamma(gamma_limit = (80, 120), p = 0.3),\n",
    "            Sharpen(p = 0.15),\n",
    "            Blur(blur_limit = 3, p = 0.2),\n",
    "            HorizontalFlip(p = 0.5),\n",
    "            VerticalFlip(p = 0.5),\n",
    "            RandomBrightnessContrast(p = 0.25),\n",
    "            CLAHE(p = 0.15),\n",
    "            ShiftScaleRotate(shift_limit = 0, scale_limit=0.3, rotate_limit=45, interpolation = 1, p = 0.3),\n",
    "            ImageCompression(quality_lower = 60, quality_upper = 100, p = 0.25),\n",
    "            MultiplicativeNoise(p=0.1)\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    \"window\":\n",
    "    {\n",
    "        \"classNumber\": 2,\n",
    "        'model': sm.Unet(\"resnext101\", classes = 1, activation = 'sigmoid'),\n",
    "        'train': True,\n",
    "        \"continue-train\": True,\n",
    "        \"max-train-images\": 3000,\n",
    "\n",
    "        \"optimizer\": tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "        \"loss\": bceDiceLoss,\n",
    "        \"metrics\": [sm.metrics.iou_score],\n",
    "        \"saved-model\": \"models-\" + MODEL_TAG + \"-window/unet.ckpt\",\n",
    "        \"batch-size\": 4,\n",
    "        \"epochs\": 10,\n",
    "        \"callbacks\": [EarlyStopping(monitor = 'val_iou_score', mode = 'max', patience = 4, verbose = 0, restore_best_weights = True)],\n",
    "\n",
    "        \"max-percent\": 0.1,\n",
    "        \n",
    "        \"transforms\": Compose(\n",
    "        [  \n",
    "            RandomGamma(gamma_limit = (80, 120), p = 0.3),\n",
    "            Sharpen(p = 0.15),\n",
    "            Blur(blur_limit = 3, p = 0.2),\n",
    "            HorizontalFlip(p = 0.5),\n",
    "            VerticalFlip(p = 0.5),\n",
    "            RandomBrightnessContrast(p = 0.25),\n",
    "            CLAHE(p = 0.15),\n",
    "            ShiftScaleRotate(shift_limit = 0, scale_limit=0.3, rotate_limit=45, interpolation = 1, p = 0.3),\n",
    "            ImageCompression(quality_lower = 60, quality_upper = 100, p = 0.25),\n",
    "            MultiplicativeNoise(p=0.1)\n",
    "        ])\n",
    "    },\n",
    "\n",
    "    \"door\":\n",
    "    {\n",
    "        \"classNumber\": 3,\n",
    "        'model': sm.Unet(\"resnext101\", classes = 1, activation = 'sigmoid'),\n",
    "        'train': True,\n",
    "        \"continue-train\": True,\n",
    "        \"max-train-images\": 2500,\n",
    "\n",
    "        \"optimizer\": tf.keras.optimizers.Adam(learning_rate = 0.001),\n",
    "        \"loss\": bceDiceLoss,\n",
    "        \"metrics\": [sm.metrics.iou_score],\n",
    "        \"saved-model\": \"models-\" + MODEL_TAG + \"-door/unet.ckpt\",\n",
    "        \"batch-size\": 4,\n",
    "        \"epochs\": 10,\n",
    "        \"callbacks\": [EarlyStopping(monitor = 'val_iou_score', mode = 'max', patience = 4, verbose = 0, restore_best_weights = True)],\n",
    "\n",
    "        \"max-percent\": 0.1,\n",
    "        \n",
    "        \"transforms\": Compose(\n",
    "        [  \n",
    "            RandomGamma(gamma_limit = (80, 120), p = 0.3),\n",
    "            Sharpen(p = 0.15),\n",
    "            Blur(blur_limit = 3, p = 0.2),\n",
    "            HorizontalFlip(p = 0.5),\n",
    "            VerticalFlip(p = 0.5),\n",
    "            RandomBrightnessContrast(p = 0.25),\n",
    "            CLAHE(p = 0.15),\n",
    "            ShiftScaleRotate(shift_limit = 0, scale_limit=0.4, rotate_limit=60, interpolation = 1, p = 0.7),\n",
    "            ImageCompression(quality_lower = 60, quality_upper = 100, p = 0.25),\n",
    "            MultiplicativeNoise(p=0.1)\n",
    "        ])\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T11:49:28.708631Z",
     "iopub.status.busy": "2022-11-24T11:49:28.708342Z",
     "iopub.status.idle": "2022-11-24T11:49:28.715104Z",
     "shell.execute_reply": "2022-11-24T11:49:28.714059Z",
     "shell.execute_reply.started": "2022-11-24T11:49:28.708606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Инициализируем Keras и ставим Seed\n",
    "sm.set_framework('tf.keras')\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T11:49:28.716973Z",
     "iopub.status.busy": "2022-11-24T11:49:28.716687Z",
     "iopub.status.idle": "2022-11-24T11:49:28.723597Z",
     "shell.execute_reply": "2022-11-24T11:49:28.722434Z",
     "shell.execute_reply.started": "2022-11-24T11:49:28.716946Z"
    }
   },
   "outputs": [],
   "source": [
    "# Все папки решения\n",
    "root = \"/notebooks\"\n",
    "trainPath = os.path.join(root, \"splitted_train_512\")\n",
    "\n",
    "testPath = os.path.join(root, \"test\")\n",
    "splittedTestPath = os.path.join(root, \"splitted_test_512\")\n",
    "\n",
    "solutionPath     = os.path.join(root, \"solution\")\n",
    "solutionFilename = os.path.join(root, \"solution_file\")\n",
    "resultPath       = os.path.join(root, \"result\")\n",
    "resultFilename   = os.path.join(root, \"result_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T11:49:28.725029Z",
     "iopub.status.busy": "2022-11-24T11:49:28.724755Z",
     "iopub.status.idle": "2022-11-24T11:49:28.735346Z",
     "shell.execute_reply": "2022-11-24T11:49:28.733883Z",
     "shell.execute_reply.started": "2022-11-24T11:49:28.725004Z"
    }
   },
   "outputs": [],
   "source": [
    "# Функция-утилита, формирующая изображения и маски из списка файлов\n",
    "def createSimpleDataset(startIndex, imagesList, masksList, images, masks, transforms):\n",
    "    for idImage, (filename, fullName) in enumerate(tqdm(imagesList.items())):\n",
    "        if masksList is not None:\n",
    "            mask = cv2.imread(masksList[filename.replace(\"_preview.png\", \".png\")])\n",
    "            mask = mask[:, :, 0]\n",
    "            mask = expand_dims(mask, axis=-1)\n",
    "        else:\n",
    "            mask = None\n",
    "\n",
    "        image = cv2.imread(fullName)\n",
    "\n",
    "        height, width, channels = image.shape\n",
    "\n",
    "        if height != IMG_HEIGHT or width != IMG_WIDTH:\n",
    "            black = zeros((IMG_HEIGHT, IMG_WIDTH, 3), dtype=uint8)\n",
    "            black[0:height, 0:width, :] = image\n",
    "            image = black\n",
    "\n",
    "\n",
    "        if transforms is not None:\n",
    "            augmented = transforms(image = array(image), mask = mask)\n",
    "            del image\n",
    "            image = augmented[\"image\"]\n",
    "            if mask is not None:\n",
    "                del mask\n",
    "                mask = augmented[\"mask\"]\n",
    "\n",
    "        if mask is not None:\n",
    "            masks[startIndex + idImage] = mask\n",
    "\n",
    "        images[startIndex + idImage] = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T11:49:28.736992Z",
     "iopub.status.busy": "2022-11-24T11:49:28.736751Z",
     "iopub.status.idle": "2022-11-24T11:49:28.748341Z",
     "shell.execute_reply": "2022-11-24T11:49:28.746889Z",
     "shell.execute_reply.started": "2022-11-24T11:49:28.736967Z"
    }
   },
   "outputs": [],
   "source": [
    "# Формирование набора данных для обучения\n",
    "def createDataset(imagesList, masksList, transformsBasic, transformsMore, useMoreProportion = 0.0):\n",
    "    dataLength = len(imagesList)\n",
    "    moreSize = int(float(dataLength) * useMoreProportion) if transformsMore is not None and useMoreProportion > 0 else 0\n",
    "    images = zeros((dataLength + moreSize, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype = uint8)\n",
    "\n",
    "    if masksList is not None:\n",
    "        masks = zeros((dataLength + moreSize, IMG_HEIGHT, IMG_WIDTH, 1), dtype = bool)\n",
    "    else:\n",
    "        masks = None\n",
    "\n",
    "    createSimpleDataset(startIndex = 0, imagesList = imagesList, masksList = masksList, images = images, masks = masks, transforms = transformsBasic)\n",
    "\n",
    "    if 0 < moreSize <= dataLength:\n",
    "        imagesNames = list(imagesList.keys())\n",
    "        shuffle(imagesNames)\n",
    "        moreImagesList = {filename: fullName for filename, fullName in imagesList.items() if filename in imagesNames[:moreSize] }\n",
    "        createSimpleDataset(startIndex = dataLength, imagesList = moreImagesList, masksList=masksList, images=images, masks=masks, transforms = transformsMore)\n",
    "\n",
    "    elif moreSize > dataLength:\n",
    "        moreSize -= dataLength\n",
    "        imagesNames = list(imagesList.keys())\n",
    "\n",
    "        if moreSize > dataLength:\n",
    "            fullImagesList = imagesNames * (moreSize // dataLength)\n",
    "            moreSize -= moreSize * (moreSize // dataLength)\n",
    "        else:\n",
    "            fullImagesList = []\n",
    "\n",
    "        if moreSize > 0:\n",
    "            shuffle(imagesNames)\n",
    "            moreImagesList = imagesNames[:moreSize]\n",
    "        else:\n",
    "            moreImagesList = []\n",
    "\n",
    "        allFiles = {filename: fullName for filename, fullName in imagesList.items() if filename in [*fullImagesList, *moreImagesList] }\n",
    "\n",
    "        createSimpleDataset(startIndex = dataLength, imagesList = allFiles, masksList = masksList, images = images, masks = masks, transforms = transformsMore)\n",
    "\n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T11:49:28.753419Z",
     "iopub.status.busy": "2022-11-24T11:49:28.753001Z",
     "iopub.status.idle": "2022-11-24T11:49:28.770299Z",
     "shell.execute_reply": "2022-11-24T11:49:28.768748Z",
     "shell.execute_reply.started": "2022-11-24T11:49:28.753383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Тренировка, продолжение тренировки или загрузка натренерованной модели, в зависимости от настроек модели\n",
    "def trainOrLoadModel(className, classData):\n",
    "    model = classData['model']\n",
    "    \n",
    "    if classData[\"train\"]:\n",
    "        print(\"\\nTrain class:\", className)\n",
    "        classPath = os.path.join(trainPath, className)\n",
    "        validFilenames = [filename for filename in os.listdir(classPath) if filename.endswith(\".png\") and not filename.endswith(\"_preview.png\")]\n",
    "\n",
    "        if classData[\"max-train-images\"] is not None:\n",
    "            shuffle(validFilenames)\n",
    "            validFilenames = validFilenames[:classData[\"max-train-images\"]]\n",
    "\n",
    "        validTrain, validTest = train_test_split(validFilenames, test_size = 0.05, random_state = SEED)\n",
    "\n",
    "        maskFilesTrain   = {filename: os.path.join(classPath, filename) for filename in validTrain}\n",
    "        imagesFilesTrain = {filename.replace(\".png\", \"_preview.png\"): os.path.join(classPath, filename.replace(\".png\", \"_preview.png\")) for filename in validTrain}\n",
    "        maskFilesTest    = {filename: os.path.join(classPath, filename) for filename in validTest}\n",
    "        imagesFilesTest  = {filename.replace(\".png\", \"_preview.png\"): os.path.join(classPath, filename.replace(\".png\", \"_preview.png\")) for filename in validTest}\n",
    "\n",
    "\n",
    "        X_train, y_train = createDataset(imagesList = imagesFilesTrain, masksList = maskFilesTrain,\n",
    "                                         transformsBasic = classData[\"transforms\"], transformsMore = None, useMoreProportion = 0)\n",
    "\n",
    "        X_test, y_test = createDataset(imagesList = imagesFilesTest, masksList = maskFilesTest,\n",
    "                                       transformsBasic = None, transformsMore = None, useMoreProportion = 0)\n",
    "\n",
    "        if classData[\"continue-train\"]:\n",
    "            model.load_weights(os.path.join(root, classData[\"saved-model\"])).expect_partial()\n",
    "\n",
    "        model.compile(classData[\"optimizer\"], classData[\"loss\"], classData[\"metrics\"])\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        model.fit(x=X_train, y=y_train, batch_size=classData[\"batch-size\"], epochs=classData[\"epochs\"], validation_data=(X_test, y_test), verbose=1,\n",
    "                  shuffle=True, callbacks=classData[\"callbacks\"])# + [TqdmCallback(verbose=2)])\n",
    "\n",
    "        del X_train\n",
    "        del y_train\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        model.save_weights(os.path.join(root, classData[\"saved-model\"]))\n",
    "\n",
    "    else:\n",
    "        model.load_weights(os.path.join(root, classData[\"saved-model\"])).expect_partial()\n",
    "\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T11:49:28.772206Z",
     "iopub.status.busy": "2022-11-24T11:49:28.771913Z",
     "iopub.status.idle": "2022-11-24T15:48:19.392698Z",
     "shell.execute_reply": "2022-11-24T15:48:19.391509Z",
     "shell.execute_reply.started": "2022-11-24T11:49:28.772180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train class: wall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3800/3800 [00:57<00:00, 66.01it/s]\n",
      "100%|██████████| 200/200 [00:02<00:00, 92.43it/s] \n",
      "2022-11-24 11:51:38.858211: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2988441600 exceeds 10% of free system memory.\n",
      "2022-11-24 11:51:43.047913: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2988441600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "950/950 [==============================] - 841s 797ms/step - loss: 0.0599 - iou_score: 0.9241 - val_loss: 0.0852 - val_iou_score: 0.8986\n",
      "Epoch 2/10\n",
      "950/950 [==============================] - 743s 782ms/step - loss: 0.0524 - iou_score: 0.9326 - val_loss: 0.0795 - val_iou_score: 0.9038\n",
      "Epoch 3/10\n",
      "950/950 [==============================] - 742s 782ms/step - loss: 0.0541 - iou_score: 0.9307 - val_loss: 0.0879 - val_iou_score: 0.8982\n",
      "Epoch 4/10\n",
      "950/950 [==============================] - 745s 784ms/step - loss: 0.0590 - iou_score: 0.9255 - val_loss: 0.0848 - val_iou_score: 0.8997\n",
      "Epoch 5/10\n",
      "950/950 [==============================] - 743s 782ms/step - loss: 0.0521 - iou_score: 0.9330 - val_loss: 0.0786 - val_iou_score: 0.9069\n",
      "Epoch 6/10\n",
      "950/950 [==============================] - 743s 782ms/step - loss: 0.0536 - iou_score: 0.9314 - val_loss: 0.0894 - val_iou_score: 0.8995\n",
      "Epoch 7/10\n",
      "950/950 [==============================] - 743s 782ms/step - loss: 0.0555 - iou_score: 0.9294 - val_loss: 0.0883 - val_iou_score: 0.8944\n",
      "Epoch 8/10\n",
      "950/950 [==============================] - 743s 782ms/step - loss: 0.0504 - iou_score: 0.9351 - val_loss: 0.0823 - val_iou_score: 0.9034\n",
      "Epoch 9/10\n",
      "950/950 [==============================] - 744s 783ms/step - loss: 0.0502 - iou_score: 0.9353 - val_loss: 0.0891 - val_iou_score: 0.8986\n",
      "\n",
      "Train class: window\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2850/2850 [00:46<00:00, 61.77it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 107.73it/s]\n",
      "2022-11-24 13:47:04.308505: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2241331200 exceeds 10% of free system memory.\n",
      "2022-11-24 13:47:06.750399: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2241331200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "713/713 [==============================] - 686s 831ms/step - loss: 0.1312 - iou_score: 0.8159 - val_loss: 0.1903 - val_iou_score: 0.7573\n",
      "Epoch 2/10\n",
      "713/713 [==============================] - 576s 807ms/step - loss: 0.1185 - iou_score: 0.8312 - val_loss: 0.1051 - val_iou_score: 0.8482\n",
      "Epoch 3/10\n",
      "713/713 [==============================] - 575s 807ms/step - loss: 0.1042 - iou_score: 0.8492 - val_loss: 0.0919 - val_iou_score: 0.8664\n",
      "Epoch 4/10\n",
      "713/713 [==============================] - 579s 811ms/step - loss: 0.0978 - iou_score: 0.8577 - val_loss: 0.1054 - val_iou_score: 0.8473\n",
      "Epoch 5/10\n",
      "713/713 [==============================] - 575s 807ms/step - loss: 0.0950 - iou_score: 0.8609 - val_loss: 0.1083 - val_iou_score: 0.8512\n",
      "Epoch 6/10\n",
      "713/713 [==============================] - 575s 806ms/step - loss: 0.0891 - iou_score: 0.8688 - val_loss: 0.1162 - val_iou_score: 0.8380\n",
      "Epoch 7/10\n",
      "713/713 [==============================] - 576s 808ms/step - loss: 0.0838 - iou_score: 0.8758 - val_loss: 0.1033 - val_iou_score: 0.8536\n",
      "\n",
      "Train class: door\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2375/2375 [00:40<00:00, 58.24it/s]\n",
      "100%|██████████| 125/125 [00:01<00:00, 97.92it/s]\n",
      "2022-11-24 14:58:15.288943: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1867776000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "594/594 [==============================] - 592s 838ms/step - loss: 0.1911 - iou_score: 0.7346 - val_loss: 0.1214 - val_iou_score: 0.8218\n",
      "Epoch 2/10\n",
      "594/594 [==============================] - 480s 808ms/step - loss: 0.1596 - iou_score: 0.7715 - val_loss: 0.1120 - val_iou_score: 0.8354\n",
      "Epoch 3/10\n",
      "594/594 [==============================] - 480s 808ms/step - loss: 0.1587 - iou_score: 0.7733 - val_loss: 0.1342 - val_iou_score: 0.8222\n",
      "Epoch 4/10\n",
      "594/594 [==============================] - 480s 808ms/step - loss: 0.1525 - iou_score: 0.7806 - val_loss: 0.1525 - val_iou_score: 0.7895\n",
      "Epoch 5/10\n",
      "594/594 [==============================] - 480s 807ms/step - loss: 0.1509 - iou_score: 0.7821 - val_loss: 0.1432 - val_iou_score: 0.8123\n",
      "Epoch 6/10\n",
      "594/594 [==============================] - 480s 809ms/step - loss: 0.1452 - iou_score: 0.7900 - val_loss: 0.1721 - val_iou_score: 0.7762\n"
     ]
    }
   ],
   "source": [
    "# Выполняем обучение, дообучение или загрузку для всех моделей классов\n",
    "for className, classData in classes.items():\n",
    "    trainOrLoadModel(className, classData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T15:48:19.397554Z",
     "iopub.status.busy": "2022-11-24T15:48:19.397169Z",
     "iopub.status.idle": "2022-11-24T15:48:19.435469Z",
     "shell.execute_reply": "2022-11-24T15:48:19.434319Z",
     "shell.execute_reply.started": "2022-11-24T15:48:19.397545Z"
    }
   },
   "outputs": [],
   "source": [
    "# Получаем словарь имён всех тестовых файлов и для каждого из них формируем список его файлов-кусочков\n",
    "testFiles = { filename: [] for filename in os.listdir(testPath) if filename.endswith(\".png\") }\n",
    "\n",
    "_ = [ testFiles[filename[:40]].append(filename) for filename in os.listdir(splittedTestPath) if filename.endswith(\".png\") and filename[:40] in testFiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T15:48:19.437397Z",
     "iopub.status.busy": "2022-11-24T15:48:19.437071Z",
     "iopub.status.idle": "2022-11-24T15:48:19.451953Z",
     "shell.execute_reply": "2022-11-24T15:48:19.450807Z",
     "shell.execute_reply.started": "2022-11-24T15:48:19.437370Z"
    }
   },
   "outputs": [],
   "source": [
    "# Если ещё нет папок для формирования решения, то создаём их\n",
    "if not os.path.exists(solutionPath):\n",
    "    os.makedirs(solutionPath)\n",
    "\n",
    "if not os.path.exists(resultPath):\n",
    "    os.makedirs(resultPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T15:48:19.453361Z",
     "iopub.status.busy": "2022-11-24T15:48:19.453036Z",
     "iopub.status.idle": "2022-11-24T15:48:29.207179Z",
     "shell.execute_reply": "2022-11-24T15:48:29.206251Z",
     "shell.execute_reply.started": "2022-11-24T15:48:19.453361Z"
    }
   },
   "outputs": [],
   "source": [
    "# Если в папках решения есть файлы, то удаляем их\n",
    "_ = [file.unlink() for file in Path(solutionPath).glob(\"*\") if file.is_file()]\n",
    "_ = [file.unlink() for file in Path(resultPath).glob(\"*\") if file.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T15:48:29.208979Z",
     "iopub.status.busy": "2022-11-24T15:48:29.208628Z",
     "iopub.status.idle": "2022-11-24T16:15:37.958302Z",
     "shell.execute_reply": "2022-11-24T16:15:37.957209Z",
     "shell.execute_reply.started": "2022-11-24T15:48:29.208947Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [27:08<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# Формируем решение, анализируя кусочки изображения, а затем собирая файл решения и файл предпросмотра решения\n",
    "for testFile, splitFiles in tqdm(testFiles.items()):\n",
    "    image = cv2.imread(os.path.join(testPath, testFile))\n",
    "    imageHeight, imageWidth = image.shape[:2]\n",
    "\n",
    "    solution = zeros((imageHeight, imageWidth, IMG_CHANNELS), dtype = uint8)\n",
    "    splitImages = zeros((len(splitFiles), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype = uint8)\n",
    "\n",
    "    for indexSplit, splitFile in enumerate(splitFiles):\n",
    "        splitImages[indexSplit, :, :, :] = cv2.imread(os.path.join(splittedTestPath, splitFile))\n",
    "\n",
    "    masks = zeros((len(splitFiles), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=uint8)\n",
    "\n",
    "    for indexClass, (className, classData) in enumerate(classes.items()):\n",
    "        # Получить предсказание модели\n",
    "        predictedMasks = (classData[\"model\"].predict(splitImages, verbose = 0).squeeze(axis = 3) * 255).astype(uint8)\n",
    "        predictedMasks[predictedMasks >= THRESHOLD] = 255\n",
    "        predictedMasks[predictedMasks < THRESHOLD]  = 0\n",
    "\n",
    "        for indexSplit in range(len(splitFiles)):\n",
    "            mask = predictedMasks[indexSplit, :, :]\n",
    "            foundPercent = cv2.countNonZero(mask) / mask.size\n",
    "\n",
    "            if foundPercent < classData[\"max-percent\"]:\n",
    "                masks[indexSplit, :, :, indexClass] = mask\n",
    "\n",
    "                for indexAnotherClass in range(len(classes)):\n",
    "                    if indexClass != indexAnotherClass:\n",
    "                        masks[indexSplit, :, :, indexAnotherClass][mask > 0] = 0\n",
    "\n",
    "    for indexSplit, splitFile in enumerate(splitFiles):\n",
    "        _, stringX, stringY = (splitFile.split(\".\")[1]).split(\"_\")\n",
    "        x, y = int(stringX), int(stringY)\n",
    "\n",
    "        mask = masks[indexSplit, :, :, :]\n",
    "\n",
    "        # Если маленькая маска выходит за пределы большой маски по высоте, то происходит уменьшение размера маленькой маски\n",
    "        if y + IMG_HEIGHT > imageHeight:\n",
    "            maskHeight = imageHeight - y\n",
    "            mask       = mask[0:maskHeight, :, :]\n",
    "        else:\n",
    "            maskHeight = IMG_HEIGHT\n",
    "\n",
    "        # Если маленькая маска выходит за пределы большой маски по ширине, то происходит уменьшение размера маленькой маски\n",
    "        if x + IMG_WIDTH > imageWidth:\n",
    "            maskWidth = imageWidth - x\n",
    "            mask    = mask[:, 0:maskWidth, :]\n",
    "        else:\n",
    "            maskWidth = IMG_WIDTH\n",
    "\n",
    "        # Добавляем маленькую маску на большую\n",
    "        solution[y:y + maskHeight, x:x + maskWidth] = mask\n",
    "\n",
    "\n",
    "    result = zeros((imageHeight, imageWidth), dtype=uint8)\n",
    "    for index, (className, classData) in enumerate(classes.items()):\n",
    "        result[solution[:,:, index] == 255] = classData[\"classNumber\"]\n",
    "\n",
    "    cv2.imwrite(os.path.join(solutionPath, testFile), image * 0.5 + solution * 0.9, [cv2.IMWRITE_PNG_COMPRESSION, 9])\n",
    "    cv2.imwrite(os.path.join(resultPath, testFile),   result,   [cv2.IMWRITE_PNG_COMPRESSION, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T16:15:37.960248Z",
     "iopub.status.busy": "2022-11-24T16:15:37.959948Z",
     "iopub.status.idle": "2022-11-24T16:15:52.968022Z",
     "shell.execute_reply": "2022-11-24T16:15:52.966920Z",
     "shell.execute_reply.started": "2022-11-24T16:15:37.960222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/notebooks/result_file.zip'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Записываем все файлы решений и предпросмотра решений в zip-файлы, чтобы было удобно их сразу скачивать и загружать на leaderboard\n",
    "shutil.make_archive(solutionFilename, \"zip\", solutionPath)\n",
    "shutil.make_archive(resultFilename,   \"zip\", resultPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-24T16:15:52.970623Z",
     "iopub.status.busy": "2022-11-24T16:15:52.970178Z",
     "iopub.status.idle": "2022-11-24T16:17:24.695118Z",
     "shell.execute_reply": "2022-11-24T16:17:24.693969Z",
     "shell.execute_reply.started": "2022-11-24T16:15:52.970585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/notebooks/models-resnext101-door.zip'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Записываем папки моделей в zip-файлы, чтобы было удобно их скачивать\n",
    "shutil.make_archive(os.path.join(root, \"models-\" + MODEL_TAG + \"-wall\"),   \"zip\", os.path.join(root, \"models-\" + MODEL_TAG + \"-wall\"))\n",
    "shutil.make_archive(os.path.join(root, \"models-\" + MODEL_TAG + \"-window\"), \"zip\", os.path.join(root, \"models-\" + MODEL_TAG + \"-window\"))\n",
    "shutil.make_archive(os.path.join(root, \"models-\" + MODEL_TAG + \"-door\"),   \"zip\", os.path.join(root, \"models-\" + MODEL_TAG + \"-door\"))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
